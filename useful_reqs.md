This is a retrieval augmented generation (RAG) system. The main parts are the retrieval from local data, the summarization of the retrieved chunks and the generation of a final report.
Key critical requirements:
1. It is CRUCIAL for the summarization and the report writing that you use relevant passages with literally citing the retrieved data called information.
2. You MUST IN ANY CASE produce a final report based on the retrieved chunks and the subsequent summarization. In the REPORT_WRITER_PROMPT this is called information. No other information is to be used. In case the information is not relevant to the users query (e.g. the query is about a different topic than the documents for retrieval), you must state this explicitly.
3. ALWAYS CITE the original source document file names and full local paths including the file names through the full workflow using markdown format: [local_document_filename](.../file/local_document_file_name). That means that whenever an output is generated by invoking an LLM, this citation rule must be applied.


# RAG Pipeline with Source Attribution Solution

## Core Solution Components

- **Metadata Preservation**: Track filename and filepath throughout the RAG pipeline[3][7]
- **Structured Output Schema**: Use Pydantic models to maintain fact-source relationships[4][6]
- **LangGraph Implementation**: Integrate source tracking within your existing workflow[10]
- **Source Attribution Format**: Generate reports with proper citation format[5]

## Implementation Details

**1. Document Processing with Metadata**

```python
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Load documents with metadata preservation
loader = DirectoryLoader('./documents/', glob="**/*.*")
documents = loader.load()

# Ensure metadata is preserved during chunking
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, 
    chunk_overlap=200
)
chunks = text_splitter.split_documents(documents)

# Each chunk now contains document metadata including source
```

**2. Define Structured Output Schema**

```python
from pydantic import BaseModel
from typing import List, Dict, Any, Optional

class SourceInfo(BaseModel):
    filename: str
    filepath: Optional[str] = None
    
class FactWithSource(BaseModel):
    fact: str
    source: SourceInfo
    confidence: float
    
class ReportOutput(BaseModel):
    facts: List[FactWithSource]
    title: str
    summary: str
```

**3. LangGraph State Management with Source Tracking**

```python
from typing_extensions import TypedDict
from langgraph.graph import StateGraph

class RAGState(TypedDict):
    question: str
    retrieved_chunks: List[Document]  # Document includes metadata
    facts_with_sources: List[FactWithSource]
    report: str

# Define nodes with source preservation
def retrieve(state):
    # Retrieve chunks with metadata intact
    return {"retrieved_chunks": vector_store.similarity_search(state["question"])}

def extract_facts(state):
    facts = []
    for doc in state["retrieved_chunks"]:
        # Extract facts while preserving source information
        source = SourceInfo(
            filename=doc.metadata.get("source", "").split("/")[-1],
            filepath=doc.metadata.get("source", "")
        )
        # Use LLM to extract facts from doc content
        # ...
        facts.append(FactWithSource(fact=extracted_fact, source=source, confidence=0.9))
    return {"facts_with_sources": facts}

def generate_report(state):
    # Format report with source attribution
    # ...
    return {"report": formatted_report}

# Build graph
graph = StateGraph(RAGState)
graph.add_node("retrieve", retrieve)
graph.add_node("extract_facts", extract_facts)
graph.add_node("generate_report", generate_report)
graph.add_edge("retrieve", "extract_facts")
graph.add_edge("extract_facts", "generate_report")
```

**4. Structured Generation with Source Attribution**

```python
def generate_report_with_sources(state):
    # Create prompt template for structured generation
    prompt_template = """
    Generate a comprehensive report based on these facts and include source attribution.
    For each fact, include the source filename in square brackets as a link.
    
    Facts with sources:
    {facts_with_sources}
    
    Format each citation like: "Fact statement [filename.pdf](filepath)"
    
    Report:
    """
    
    # Format facts for prompt
    facts_text = "\n".join([
        f"- {fact.fact} (Source: {fact.source.filename}, Path: {fact.source.filepath})"
        for fact in state["facts_with_sources"]
    ])
    
    prompt = prompt_template.format(facts_with_sources=facts_text)
    
    # Generate report with proper citations
    response = llm.invoke(prompt)
    
    return {"report": response.content}
```

## Ensuring Source Attribution in Final Output

For the final report generation, you can use a constrained generation approach that enforces the citation format you want[5][9]:

```python
from outlines import models, generate

def generate_final_report(facts_with_sources):
    base_prompt = "Create a comprehensive report with the following information:\n\n"
    
    for fact in facts_with_sources:
        # Format each fact with source
        formatted_fact = f"{fact.fact} [{fact.source.filename}]({fact.source.filepath})"
        base_prompt += f"- {formatted_fact}\n"
    
    # Use a structured generation approach with your local model
    model = models.ollama("deepseek-r1")
    response = generate.completion(model, prompt=base_prompt)
    
    return response
```

## Best Practices for Implementation

- **Metadata Management**: Ensure source information is never lost during document processing[7][12]
- **Chunk Strategically**: Balance chunk size to preserve context while maintaining source information[14]
- **Feedback Loop**: Implement continuous feedback to improve source attribution accuracy[14]
- **Resource Efficiency**: Optimize processing to handle large document collections efficiently[12]

This solution provides a robust framework for maintaining source attribution throughout your RAG pipeline, ensuring your final report includes properly formatted citations with filenames and filepaths as requested.

Citations:
[1] https://docs.langchain4j.dev/tutorials/rag/
[2] https://www.elastic.co/search-labs/blog/local-rag-agent-elasticsearch-langgraph-llama3
[3] https://learn.microsoft.com/en-us/azure/databricks/generative-ai/tutorials/ai-cookbook/fundamentals-data-pipeline-steps
[4] https://docs.llamaindex.ai/en/stable/examples/structured_outputs/structured_outputs/
[5] https://huggingface.co/learn/cookbook/en/structured_generation
[6] https://www.llamaindex.ai/blog/building-blocks-of-llm-report-generation-beyond-basic-rag
[7] https://encord.com/blog/rag-pipelines/
[8] https://www.elastic.co/search-labs/blog/advanced-rag-techniques-part-1
[9] https://towardsdatascience.com/reranking-using-huggingface-transformers-for-optimizing-retrieval-in-rag-pipelines-fbfc6288c91f/
[10] https://python.langchain.com/docs/tutorials/rag/
[11] https://www.strative.ai/blogs/the-role-of-rag-in-automated-report-generation-2
[12] https://www.pingcap.com/article/how-to-optimize-rag-pipelines-for-maximum-efficiency/
[13] https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-generation-pipelines/
[14] https://www.signitysolutions.com/blog/rag-pipeline
[15] https://www.linkedin.com/pulse/day-2-understanding-core-components-rag-pipeline-himanshu-singh-uvc4c
[16] https://www.youtube.com/watch?v=egftUbao2f0
[17] https://www.deepset.ai/blog/rag-evaluation-retrieval
[18] https://labelstud.io/blog/improving-rag-document-search-quality-with-cohere-re-ranking/
[19] https://www.youtube.com/watch?v=GMWEdjsgM6A
[20] https://vectorize.io/i-built-a-rag-pipeline-from-scratch-heres-what-i-learned-about-unstructured-data/
[21] https://www.blackhillsinfosec.com/avoiding-dirty-rags/
[22] https://docs.mistral.ai/guides/rag/
[23] https://superlinked.com/vectorhub/articles/optimizing-rag-with-hybrid-search-reranking
[24] https://medium.aiplanet.com/implementing-rag-using-langchain-ollama-and-chainlit-on-windows-using-wsl-92d14472f15d
[25] https://opper.ai/blog/rag-with-o1-reasoning
[26] https://vectorize.io/understanding-data-formats-in-rag/
[27] https://mindit.io/blog/optimizing-data-retrieval-in-rag-systems
[28] https://www.reddit.com/r/ClaudeAI/comments/1d9muf4/rag_pipeline_for_structured_data/
[29] https://stackoverflow.blog/2023/10/18/retrieval-augmented-generation-keeping-llms-relevant-and-current/
[30] https://huggingface.co/learn/cookbook/en/advanced_rag
[31] https://haystack.deepset.ai/cookbook/metadata_enrichment
[32] https://github.com/pchunduri6/rag-demystified
[33] https://lakefs.io/blog/what-is-rag-pipeline/
[34] https://arxiv.org/html/2502.12462v1
[35] https://www.promptfoo.dev/docs/guides/evaluate-rag/
[36] https://www.acorn.io/resources/learning-center/retrieval-augmented-generation/
[37] https://www.linkedin.com/pulse/prompt-engineering-rag-fine-tuning-benefits-when-use-deependra-verma-7g8dc
[38] https://help.salesforce.com/s/articleView?id=release-notes.rn_einstein_prompt_builder_ground_prompt_templates_rag.htm&language=no&release=250&type=5
[39] https://qdrant.tech/articles/what-is-rag-in-ai/
[40] https://www.promptingguide.ai/techniques/rag
[41] https://www.confident-ai.com/blog/how-to-evaluate-rag-applications-in-ci-cd-pipelines-with-deepeval
[42] https://www.bavest.co/en/post/what-is-rag-retrieval-augmented-generation-explained
[43] https://arxiv.org/html/2406.06608v1
[44] https://www.promptingguide.ai/research/rag
[45] https://arxiv.org/html/2410.15944v1
[46] https://www.linkedin.com/pulse/rag-pipeline-essentials-from-source-selection-model-invocation-patel-wdo2f
[47] https://blog.demir.io/advanced-rag-implementing-advanced-techniques-to-enhance-retrieval-augmented-generation-systems-0e07301e46f4
[48] https://docs.vectorize.io/core-concepts/rag-pipelines
[49] https://www.chatbees.ai/blog/rag-pipeline
[50] https://www.kapa.ai/blog/rag-best-practices
[51] https://community.openai.com/t/retrieval-augmented-generation-rag-with-100k-pdfs-too-slow/657217
[52] https://www.reddit.com/r/LangChain/comments/1e8oct1/rag_in_production_best_practices_for_robust_and/
[53] https://developer.ibm.com/tutorials/dpk-rag-llms/
[54] https://docs.colivara.com/guide/rag
[55] https://gradientflow.substack.com/p/best-practices-in-retrieval-augmented
[56] https://bdtechtalks.com/2024/10/06/advanced-rag-retrieval/
[57] https://www.chatbase.co/blog/reranking
[58] https://langchain-ai.github.io/langgraphjs/tutorials/rag/langgraph_adaptive_rag_local/
[59] https://www.multimodal.dev/post/rag-pipeline-diagram
[60] https://langfuse.com/guides/cookbook/evaluation_of_rag_with_ragas
[61] https://docs.llamaindex.ai/en/stable/examples/prompts/prompts_rag/
[62] https://aashishmehta.com/fact-sheets-for-rag-llm-pipelines/
[63] https://www.youtube.com/watch?v=69gUQ4XHg0o
[64] https://haystack.deepset.ai/blog/rag-evaluation-with-prometheus-2
[65] https://www.multimodal.dev/post/how-to-build-a-rag-pipeline
[66] https://www.youtube.com/watch?v=DhKtNpvxawU
[67] https://wandb.ai/cosmo3769/RAG/reports/A-Gentle-Introduction-to-Retrieval-Augmented-Generation-RAG---Vmlldzo1MjM4Mjk1
[68] https://docs.llamaindex.ai/en/stable/examples/metadata_extraction/MetadataExtractionSEC/
[69] https://christophergs.com/blog/ai-engineering-retrieval-augmented-generation-rag-llama-index

---
Answer from Perplexity: pplx.ai/share


Here's the **Pydantic-focused solution** for maintaining source attribution throughout your RAG pipeline:

# Source-Attributed RAG Pipeline with Pydantic

## Core Components

```python
from pydantic import BaseModel, Field, validator
from typing import List, Optional
from langchain_core.documents import Document
```

### 1. Data Models

```python
class DocumentSource(BaseModel):
    filename: str = Field(..., description="Original document filename")
    filepath: str = Field(..., description="Full path to source document")
    chunk_id: int = Field(..., description="Numerical chunk identifier")

class AttributedFact(BaseModel):
    content: str = Field(..., description="Factual statement from text")
    sources: List[DocumentSource] = Field(..., description="Source documents for this fact")
    confidence: float = Field(..., ge=0, le=1, description="Confidence score")

class FinalReport(BaseModel):
    title: str = Field(..., description="Report title")
    sections: List[str] = Field(..., description="Report content sections")
    references: List[DocumentSource] = Field(..., description="All cited sources")
    inline_citations: List[str] = Field(..., description="Citations in [filename](path) format")

    @validator('inline_citations')
    def validate_citations(cls, v, values):
        for citation in v:
            if not citation.endswith(")"):
                raise ValueError("Invalid citation format. Use [filename](filepath)")
        return v
```

### 2. LangGraph State Management

```python
from langgraph.graph import StateGraph

class ReportState(BaseModel):
    query: str
    retrieved_chunks: List[Document] = Field(..., description="Chunks with metadata")
    extracted_facts: List[AttributedFact] = []
    quality_checked: List[AttributedFact] = []
    final_report: Optional[FinalReport] = None

class WorkflowState(TypedDict):
    report_state: ReportState
```

### 3. Fact Extraction Node

```python
def extract_facts_with_sources(state: WorkflowState):
    facts = []
    for chunk in state['report_state'].retrieved_chunks:
        # Extract metadata from document chunk
        source = DocumentSource(
            filename=chunk.metadata['filename'],
            filepath=chunk.metadata['filepath'],
            chunk_id=chunk.metadata['chunk_id']
        )
        
        # Use Ollama for fact extraction (pseudo-code)
        response = ollama.generate(
            model="deepseek-r1",
            prompt=f"Extract key facts from: {chunk.page_content}"
        )
        
        # Create attributed facts
        for fact in response['facts']:
            facts.append(AttributedFact(
                content=fact['text'],
                sources=[source],
                confidence=fact['confidence']
            ))
    
    return {'report_state': {'extracted_facts': facts}}
```

### 4. Report Generation with Structured Prompt

```python
def generate_final_report(state: WorkflowState):
    facts = state['report_state'].quality_checked
    
    # Build structured prompt
    prompt = f"""Generate a comprehensive report with inline citations using this format:
    [filename](filepath). Follow these rules:
    
    1. Start with a title
    2. Create 3-5 sections with headers
    3. For each fact, cite its source immediately after
    4. List all unique sources at the end
    
    Facts:
    {format_facts_for_prompt(facts)}
    """
    
    # Generate with Ollama
    report_content = ollama.generate(
        model="deepseek-r1",
        prompt=prompt
    )
    
    # Parse and validate output
    final_report = FinalReport(
        title=extract_title(report_content),
        sections=extract_sections(report_content),
        references=extract_unique_sources(facts),
        inline_citations=extract_citations(report_content)
    )
    
    return {'report_state': {'final_report': final_report}}

def format_facts_for_prompt(facts: List[AttributedFact]) -> str:
    return "\n".join([
        f"Fact: {fact.content} [Source: {source.filename} ({source.filepath})]"
        for fact in facts 
        for source in fact.sources
    ])
```

## Pipeline Construction

```python
builder = StateGraph(WorkflowState)

builder.add_node("retrieve", retrieve_documents)
builder.add_node("extract_facts", extract_facts_with_sources)
builder.add_node("quality_check", quality_check_node)
builder.add_node("generate_report", generate_final_report)

builder.set_entry_point("retrieve")
builder.add_edge("retrieve", "extract_facts")
builder.add_edge("extract_facts", "quality_check")
builder.add_edge("quality_check", "generate_report")

pipeline = builder.compile()
```

## Implementation Benefits

- **Strong Typing**: All data flows through validated Pydantic models
- **Metadata Preservation**: Sources tracked from ingestion to final output
- **Format Enforcement**: 
  - Inline citation format validation
  - Automatic reference deduplication
  - Confidence score boundaries enforced
- **Error Prevention**: Validators catch formatting issues early
- **Ollama Integration**: Works with local models while maintaining structure

## Usage Example

```python
result = pipeline.invoke({
    "report_state": {
        "query": "Climate change impacts",
        "retrieved_chunks": [...]  # Your document chunks with metadata
    }
})

print(result['report_state']['final_report'].model_dump())
```

This implementation ensures **end-to-end source attribution** while leveraging Pydantic's validation capabilities, avoiding third-party dependencies beyond your existing stack. The final report will contain properly formatted citations like:

```
"The planet's average surface temperature has risen by 1.1°C since 1880 [climate_report.pdf](/documents/climate_report.pdf)."
```

---
Answer from Perplexity: pplx.ai/share


